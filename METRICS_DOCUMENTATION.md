# Fairness Metrics å®ç°æ–‡æ¡£

## âœ… å®Œæˆçš„åŠŸèƒ½

### 1. Overall Fairness Scoreï¼ˆç»¼åˆå…¬å¹³æ€§åˆ†æ•°ï¼‰

#### åç«¯å®ç° (`backend/app.py`)

**å‡½æ•°ä½ç½®**: `calculate_overall_fairness_score(metrics)` (ç¬¬85-126è¡Œ)

```python
def calculate_overall_fairness_score(metrics):
    """
    Calculate Overall Fairness Score from individual fairness metrics.
    ç»¼åˆå…¬å¹³æ€§åˆ†æ•° = æ‰€æœ‰fairness metricsçš„å¹³å‡å€¼ï¼ˆè¶Šå°è¶Šå…¬å¹³ï¼‰
    
    Args:
        metrics (dict): Dictionary containing fairness metrics
    
    Returns:
        float: Overall fairness score (lower is better, 0 is perfect fairness)
    """
    fairness_metric_names = [
        'BNC', 'BPC', 'CUAE', 'EOpp', 'EO', 
        'FDRP', 'FORP', 'FNRB', 'FPRB', 
        'NPVP', 'OAE', 'PPVP', 'SP'
    ]
    
    fairness_values = []
    
    for metric_name in fairness_metric_names:
        if metric_name in metrics:
            metric_value = metrics[metric_name]
            
            # Handle different metric formats
            if isinstance(metric_value, dict):
                # Nested dict (e.g., {'SEX': 0.001, 'MARRIAGE': 0.002})
                for v in metric_value.values():
                    if isinstance(v, (int, float, np.number)):
                        fairness_values.append(float(v))
            elif isinstance(metric_value, (int, float, np.number)):
                # Direct value
                fairness_values.append(float(metric_value))
    
    # Calculate mean of all fairness values
    if fairness_values:
        overall_score = np.mean(fairness_values)
    else:
        overall_score = 0.0
    
    return float(overall_score)
```

#### è®¡ç®—é€»è¾‘

1. **æå–æ‰€æœ‰ fairness metrics çš„å€¼**
   - æ”¯æŒåµŒå¥—å­—å…¸æ ¼å¼ï¼ˆå¦‚ `{'SEX': 0.001, 'MARRIAGE': 0.002}`ï¼‰
   - æ”¯æŒç›´æ¥æ•°å€¼æ ¼å¼

2. **è®¡ç®—å¹³å‡å€¼**
   - ä½¿ç”¨ `np.mean()` è®¡ç®—æ‰€æœ‰ fairness å€¼çš„å¹³å‡
   - **è¶Šå°è¶Šå…¬å¹³**ï¼Œ0 è¡¨ç¤ºå®Œç¾å…¬å¹³

3. **è‡ªåŠ¨æ·»åŠ åˆ° metrics**
   - æ¯æ¬¡è°ƒç”¨ `evaluator.evaluate()` åè‡ªåŠ¨æ·»åŠ 
   - ä½œä¸º `metrics['Overall_Fairness']` è¿”å›

#### è°ƒç”¨ä½ç½®

åç«¯åœ¨ä»¥ä¸‹4å¤„è°ƒç”¨ `evaluate()` åéƒ½ä¼šæ·»åŠ  Overall_Fairnessï¼š

1. **åˆå§‹åŒ–æ—¶** (`api/debias/init`)
   ```python
   init_metrics = evaluator.evaluate(...)
   init_metrics['Overall_Fairness'] = calculate_overall_fairness_score(init_metrics)
   ```

2. **Step by Step** (`api/debias/{id}/step`)
   ```python
   metrics = job['evaluator'].evaluate(...)
   metrics['Overall_Fairness'] = calculate_overall_fairness_score(metrics)
   ```

3. **Run All Steps - æ¯è½®** (`_run_full_process_thread`)
   ```python
   metrics = job['evaluator'].evaluate(...)
   metrics['Overall_Fairness'] = calculate_overall_fairness_score(metrics)
   ```

4. **Run All Steps - æœ€ç»ˆç»“æœ** (`_run_full_process_thread`)
   ```python
   final_metrics = job['evaluator'].evaluate(...)
   final_metrics['Overall_Fairness'] = calculate_overall_fairness_score(final_metrics)
   ```

---

### 2. å‰ç«¯å›¾è¡¨æ˜¾ç¤º

#### é»˜è®¤æ˜¾ç¤º

**Overall Fairness Score** ä½œä¸ºé»˜è®¤é€‰é¡¹æ˜¾ç¤ºåœ¨å›¾è¡¨ä¸­ï¼š

```html
<select class="metric-selector" id="metricSelector">
  <option value="Overall_Fairness" selected>
    Overall Fairness Score (ç»¼åˆå…¬å¹³æ€§)
  </option>
  <optgroup label="Individual Metrics">
    <option value="BNC">BNC - Between Negative Classes</option>
    <option value="BPC">BPC - Between Positive Classes</option>
    <!-- ... å…¶ä»– metrics ... -->
  </optgroup>
</select>
```

#### ç”¨æˆ·äº¤äº’

1. **é»˜è®¤çŠ¶æ€**
   - å›¾è¡¨æ˜¾ç¤º **Overall Fairness Score** éš iteration çš„å˜åŒ–
   - Yè½´ï¼šOverall Fairness å€¼
   - Xè½´ï¼šIteration è½®æ•°

2. **åˆ‡æ¢ Metric**
   - ç”¨æˆ·é€šè¿‡ä¸‹æ‹‰é€‰æ‹©æ¡†é€‰æ‹©å…¶ä»– metric
   - å›¾è¡¨ç«‹å³æ›´æ–°æ˜¾ç¤ºé€‰ä¸­çš„ metric
   - æ¯ä¸ª metric éƒ½æœ‰å®Œæ•´çš„æè¿°

3. **åŠ¨æ€ Yè½´**
   - Yè½´èŒƒå›´æ ¹æ®æ•°æ®è‡ªåŠ¨è°ƒæ•´
   - é€‚åº”å°æ•°å€¼çš„ fairness metrics
   - ä½¿ç”¨ç§‘å­¦è®¡æ•°æ³•æ˜¾ç¤ºï¼ˆå¦‚ `1.2e-4`ï¼‰

---

## ğŸ“Š Fairness Metrics è¯´æ˜

### æ”¯æŒçš„ Metrics

| Metric | å…¨ç§° | è¯´æ˜ |
|--------|------|------|
| **Overall_Fairness** | Overall Fairness Score | **ç»¼åˆå…¬å¹³æ€§åˆ†æ•°**ï¼ˆæ‰€æœ‰ metrics å¹³å‡å€¼ï¼‰ |
| BNC | Between Negative Classes | è´Ÿç±»åˆ«é—´å·®å¼‚ |
| BPC | Between Positive Classes | æ­£ç±»åˆ«é—´å·®å¼‚ |
| CUAE | Conditional Use Accuracy Equality | æ¡ä»¶ä½¿ç”¨å‡†ç¡®æ€§å¹³ç­‰ |
| EOpp | Equal Opportunity | æœºä¼šå¹³ç­‰ |
| EO | Equalized Odds | å¹³è¡¡èµ”ç‡ |
| FDRP | False Discovery Rate Parity | é”™è¯¯å‘ç°ç‡å‡ç­‰ |
| FORP | False Omission Rate Parity | é”™è¯¯é—æ¼ç‡å‡ç­‰ |
| FNRB | False Negative Rate Balance | å‡é˜´æ€§ç‡å¹³è¡¡ |
| FPRB | False Positive Rate Balance | å‡é˜³æ€§ç‡å¹³è¡¡ |
| NPVP | Negative Predictive Value Parity | è´Ÿé¢„æµ‹å€¼å‡ç­‰ |
| OAE | Overall Accuracy Equality | æ•´ä½“å‡†ç¡®æ€§å¹³ç­‰ |
| PPVP | Positive Predictive Value Parity | æ­£é¢„æµ‹å€¼å‡ç­‰ |
| SP | Statistical Parity | ç»Ÿè®¡å‡ç­‰ |

### Metric è§£é‡Š

- **æ‰€æœ‰ fairness metrics çš„å€¼è¶Šå°è¶Šå¥½**
- **0 è¡¨ç¤ºå®Œç¾å…¬å¹³**ï¼ˆä¸¤ä¸ªç¾¤ä½“å®Œå…¨ç›¸åŒï¼‰
- **å€¼è¶Šå¤§è¡¨ç¤ºä¸å…¬å¹³ç¨‹åº¦è¶Šé«˜**

---

## ğŸ¯ æ•°æ®æµç¨‹

### å®Œæ•´æµç¨‹

```
1. ç”¨æˆ·é€‰æ‹©æ•°æ® & è¿è¡Œ
   â†“
2. åç«¯ init_debias
   â”œâ”€ evaluator.evaluate()
   â”œâ”€ è®¡ç®—æ‰€æœ‰ individual metrics (BNC, BPC, ...)
   â”œâ”€ calculate_overall_fairness_score()
   â””â”€ æ·»åŠ  metrics['Overall_Fairness']
   â†“
3. åç«¯ run_full / step
   æ¯è½® iteration:
   â”œâ”€ BM (if enabled)
   â”œâ”€ AE (if enabled)
   â”œâ”€ evaluator.evaluate()
   â”œâ”€ calculate_overall_fairness_score()
   â””â”€ metrics['Overall_Fairness'] æ·»åŠ åˆ° history
   â†“
4. å‰ç«¯è½®è¯¢ /api/debias/{id}/status
   â”œâ”€ è·å– history (åŒ…å«æ¯è½®çš„ Overall_Fairness)
   â”œâ”€ ç”¨æˆ·é€‰æ‹©è¦æ˜¾ç¤ºçš„ metric
   â””â”€ å›¾è¡¨å®æ—¶æ›´æ–°
```

### API è¿”å›æ•°æ®ç»“æ„

```json
{
  "status": "success",
  "data": {
    "history": [
      {
        "iteration": 1,
        "metrics": {
          "ACC": 0.7845,
          "F1": 0.6234,
          "BNC": 0.000123,
          "BPC": 0.000234,
          "EOpp": 0.000345,
          "Overall_Fairness": 0.000267,  // â† ç»¼åˆåˆ†æ•°
          // ... å…¶ä»– metrics
        }
      },
      {
        "iteration": 2,
        "metrics": {
          "ACC": 0.7892,
          "Overall_Fairness": 0.000145,  // â† è¶Šæ¥è¶Šå°ï¼Œè¶Šæ¥è¶Šå…¬å¹³
          // ...
        }
      }
    ]
  }
}
```

---

## ğŸ” ä»£ç ä½ç½®æ€»ç»“

### åç«¯ (`backend/app.py`)

| åŠŸèƒ½ | ä½ç½® | è¯´æ˜ |
|------|------|------|
| `calculate_overall_fairness_score()` | ç¬¬85-126è¡Œ | è®¡ç®—ç»¼åˆåˆ†æ•° |
| åˆå§‹åŒ–æ·»åŠ  | ç¬¬403è¡Œ | `init_metrics['Overall_Fairness'] = ...` |
| Stepæ·»åŠ  | ç¬¬575è¡Œ | `metrics['Overall_Fairness'] = ...` |
| Run Allæ·»åŠ  | ç¬¬686è¡Œ | `metrics['Overall_Fairness'] = ...` |
| Finalæ·»åŠ  | ç¬¬745è¡Œ | `final_metrics['Overall_Fairness'] = ...` |

### å‰ç«¯ (`frontend/index.html`)

| åŠŸèƒ½ | ä½ç½® | è¯´æ˜ |
|------|------|------|
| é»˜è®¤é€‰ä¸­ | ç¬¬883è¡Œ | `const currentSelectedMetric = state.selectedMetric \|\| 'Overall_Fairness'` |
| ä¸‹æ‹‰é€‰é¡¹ | ç¬¬958-964è¡Œ | `<option value="Overall_Fairness" selected>` |
| å›¾è¡¨æ¸²æŸ“ | ç¬¬889-894è¡Œ | ä» `h.metrics[currentSelectedMetric]` è·å–å€¼ |
| äº‹ä»¶ç›‘å¬ | ç¬¬1034-1039è¡Œ | metric selector å˜åŒ–æ—¶é‡æ–°æ¸²æŸ“ |

---

## âœ… éªŒè¯æ¸…å•

- [x] åç«¯è®¡ç®— Overall Fairness Score
- [x] åç«¯åœ¨æ‰€æœ‰ evaluate() åæ·»åŠ  Overall_Fairness
- [x] å‰ç«¯é»˜è®¤æ˜¾ç¤º Overall Fairness
- [x] ç”¨æˆ·å¯ä»¥åˆ‡æ¢æ˜¾ç¤ºå…¶ä»– individual metrics
- [x] å›¾è¡¨åŠ¨æ€æ›´æ–°
- [x] Yè½´è‡ªåŠ¨ç¼©æ”¾
- [x] æ‰€æœ‰è®¡ç®—é€»è¾‘åœ¨åç«¯ï¼ˆä¸æ˜¯å‰ç«¯éšä¾¿ç®—çš„ï¼‰
- [ ] å®é™…è¿è¡Œæµ‹è¯•ï¼ˆéœ€è¦ç”¨æˆ·æ‰§è¡Œï¼‰

---

## ğŸš€ ä½¿ç”¨æ–¹å¼

### å¯åŠ¨æµ‹è¯•

1. **é‡å¯åç«¯**
   ```bash
   cd backend
   conda activate bmwithae
   python app.py
   ```

2. **åˆ·æ–°å‰ç«¯**
   - é‡æ–°æ‰“å¼€ `frontend/index.html`

3. **è¿è¡Œæµ‹è¯•**
   - Load Credit æ•°æ®
   - ç‚¹å‡» "Run All Steps"
   - è§‚å¯Ÿå›¾è¡¨ï¼š
     - é»˜è®¤æ˜¾ç¤º **Overall Fairness Score**
     - å€¼åº”è¯¥éš iteration é€’å‡ï¼ˆè¶Šæ¥è¶Šå…¬å¹³ï¼‰
     - å¯ä»¥åˆ‡æ¢åˆ°å…¶ä»– metrics æŸ¥çœ‹

4. **éªŒè¯æ•°æ®æ¥æº**
   - æ‰“å¼€æµè§ˆå™¨å¼€å‘è€…å·¥å…·
   - Networkæ ‡ç­¾ â†’ æŸ¥çœ‹ `/api/debias/{id}/status`
   - å“åº”ä¸­åº”åŒ…å« `metrics['Overall_Fairness']`

---

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **æ‰€æœ‰ fairness metrics éƒ½æ˜¯è¶Šå°è¶Šå¥½**
   - Overall_Fairness = 0ï¼šå®Œç¾å…¬å¹³
   - Overall_Fairness > 0ï¼šå­˜åœ¨ä¸å…¬å¹³

2. **è®¡ç®—å®Œå…¨åœ¨åç«¯**
   - å‰ç«¯åªè´Ÿè´£æ˜¾ç¤º
   - ä¸ä¼šå‡ºç°å‰åç«¯è®¡ç®—ä¸ä¸€è‡´çš„é—®é¢˜

3. **å®æ—¶æ›´æ–°**
   - Run All Steps æ¨¡å¼ï¼šæ¯è½®å®Œæˆåç«‹å³æ›´æ–°
   - Step by Step æ¨¡å¼ï¼šæ¯æ¬¡ç‚¹å‡»ç«‹å³æ›´æ–°

4. **æ‰©å±•æ€§**
   - å¦‚éœ€æ·»åŠ æ–°çš„ fairness metricï¼Œåªéœ€ï¼š
     1. åœ¨ `code_v_0_1/eval.py` ä¸­å®ç°
     2. åœ¨ `backend/app.py` çš„ `fairness_metric_names` åˆ—è¡¨ä¸­æ·»åŠ 
     3. åœ¨å‰ç«¯ `metricDescriptions` ä¸­æ·»åŠ æè¿°

---

**å®ç°å®Œæˆï¼æ‰€æœ‰ metrics è®¡ç®—éƒ½åœ¨åç«¯ï¼Œç¡®ä¿æ•°æ®å‡†ç¡®æ€§ï¼** âœ¨



